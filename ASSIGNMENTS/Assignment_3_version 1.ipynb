{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X6uqg2BFvE7",
        "outputId": "1b7e4ade-8d81-4181-81c3-347df631a210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 150 images belonging to 1 classes.\n",
            "Found 157 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "import numpy as np\n",
        "train_path ='/content/drive/MyDrive/archive/train_data'\n",
        "test_path='/content/drive/MyDrive/archive/test_data'\n",
        "train_gen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "test_gen=ImageDataGenerator(rescale=1./255)\n",
        "train=train_gen.flow_from_directory(train_path,target_size=(224,224),batch_size=22,class_mode='categorical')\n",
        "test=test_gen.flow_from_directory(test_path,target_size=(224,224),batch_size=22,class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG MODEL"
      ],
      "metadata": {
        "id": "Vyp0osK9GofR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now we import the model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
        "#adding the preprocessing layer to the front of VGG as that is the input we are using\n",
        "vgg=VGG16(include_top=False,weights='imagenet',input_shape=(224,224,3))\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable=False\n",
        "x=Flatten()(vgg.output)\n",
        "\n",
        "#output layer\n",
        "prediction=Dense(3,activation='softmax')(x)\n",
        "#Create VGG16 Model\n",
        "model=Model(inputs=vgg.input,outputs=prediction)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(train,validation_data=test,epochs=10,steps_per_epoch=len(train),validation_steps=len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL2EciOzGqxO",
        "outputId": "d2bbc1aa-8ea0-452a-cbca-510a58fbc8ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3914830c0113>:16: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train,validation_data=test,epochs=10,steps_per_epoch=len(train),validation_steps=len(test))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 309s 46s/step - loss: 3.4234 - accuracy: 0.3267 - val_loss: 3.4212 - val_accuracy: 0.3631\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 92s 15s/step - loss: 3.4224 - accuracy: 0.3333 - val_loss: 3.4237 - val_accuracy: 0.3822\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 121s 19s/step - loss: 3.4202 - accuracy: 0.3067 - val_loss: 3.4336 - val_accuracy: 0.4013\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 90s 15s/step - loss: 3.4369 - accuracy: 0.3533 - val_loss: 3.4077 - val_accuracy: 0.3439\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 89s 14s/step - loss: 3.4360 - accuracy: 0.3267 - val_loss: 3.4322 - val_accuracy: 0.4331\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 92s 14s/step - loss: 3.4128 - accuracy: 0.3667 - val_loss: 3.4376 - val_accuracy: 0.3376\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 90s 14s/step - loss: 3.4416 - accuracy: 0.3333 - val_loss: 3.4390 - val_accuracy: 0.4140\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 91s 14s/step - loss: 3.4281 - accuracy: 0.3067 - val_loss: 3.4169 - val_accuracy: 0.4395\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 91s 14s/step - loss: 3.4265 - accuracy: 0.3267 - val_loss: 3.4173 - val_accuracy: 0.3121\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 92s 14s/step - loss: 3.4394 - accuracy: 0.3667 - val_loss: 3.4580 - val_accuracy: 0.4522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b0757cd60>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## resnet 50"
      ],
      "metadata": {
        "id": "1ZLuLZdgLM22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "resnet=ResNet50(include_top=False,input_shape=(224,224,3))\n",
        "for layer in resnet.layers:\n",
        "  layer.trainable=False\n",
        "x=Flatten()(resnet.output)\n",
        "out=Dense(4,activation='softmax')(x)\n",
        "res_model=Model(inputs=resnet.input,outputs=out)\n",
        "res_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "res_model.fit(train,epochs=5,validation_data=test,steps_per_epoch=len(train),validation_steps=len(test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljn8UwPvLHN3",
        "outputId": "fdd8c71b-0654-4426-d7db-7ab324c80a5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 4s 0us/step\n",
            "Epoch 1/5\n",
            "7/7 [==============================] - 101s 15s/step - loss: 7.2561 - accuracy: 0.1200 - val_loss: 7.2690 - val_accuracy: 0.1529\n",
            "Epoch 2/5\n",
            "7/7 [==============================] - 92s 14s/step - loss: 7.2590 - accuracy: 0.0867 - val_loss: 7.2674 - val_accuracy: 0.1656\n",
            "Epoch 3/5\n",
            "7/7 [==============================] - 91s 14s/step - loss: 7.2650 - accuracy: 0.1467 - val_loss: 7.2417 - val_accuracy: 0.1656\n",
            "Epoch 4/5\n",
            "7/7 [==============================] - 90s 14s/step - loss: 7.2268 - accuracy: 0.1533 - val_loss: 7.2468 - val_accuracy: 0.1338\n",
            "Epoch 5/5\n",
            "7/7 [==============================] - 121s 19s/step - loss: 7.2862 - accuracy: 0.1067 - val_loss: 7.2631 - val_accuracy: 0.1911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b0638a170>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}